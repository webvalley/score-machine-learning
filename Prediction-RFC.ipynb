{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split as splt\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold as rskf\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from scipy.sparse import csr_matrix \n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_coltype(df, headers):\n",
    "    boolval = []\n",
    "    headers = headers + [\"subject_id\", \"ScoreClass\", \"visit\"]\n",
    "    for header in headers:\n",
    "        boolval.append(df.columns.str.startswith(header))\n",
    "    return df[df.columns[np.any(boolval, axis=0)]]\n",
    "def prepare_dataset(X, y, x_ind, y_ind):\n",
    "    X_, y_ = [], []\n",
    "    for i in x_ind:\n",
    "        X_ = X_ + X[i]\n",
    "    for i in y_ind:\n",
    "        y_ = y_ + y[i]\n",
    "    return (X_,y_)\n",
    "def bootstrap_ci(x, B=1000, alpha=0.05, seed=42):\n",
    "    \"\"\"Computes the (1-alpha) Bootstrap confidence interval\n",
    "    from empirical bootstrap distribution of sample mean.\n",
    "\n",
    "    The lower and upper confidence bounds are the (B*alpha/2)-th\n",
    "    and B * (1-alpha/2)-th ordered means, respectively.\n",
    "    For B = 1000 and alpha = 0.05 these are the 25th and 975th\n",
    "    ordered means.\n",
    "    \"\"\"\n",
    "\n",
    "    x_arr = np.ravel(x)\n",
    "\n",
    "    if B < 2:\n",
    "        raise ValueError(\"B must be >= 2\")\n",
    "\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"alpha must be in [0, 1]\")\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    bmean = np.empty(B, dtype=np.float)\n",
    "    for b in range(B):\n",
    "        idx = np.random.random_integers(0, x_arr.shape[0]-1, x_arr.shape[0])\n",
    "        bmean[b] = np.mean(x_arr[idx])\n",
    "\n",
    "    bmean.sort()\n",
    "    lower = int(B * (alpha * 0.5))\n",
    "    upper = int(B * (1 - (alpha * 0.5)))\n",
    "\n",
    "    return (bmean[lower], bmean[upper])\n",
    "\n",
    "def get_data_for_trial(df, headers, x_ind, y_ind):\n",
    "    df_specific = prep_coltype(df, headers)\n",
    "    d = {i: df.loc[df.subject_id == i, df.columns] for i in range(df.subject_id.iat[-1]+1)}\n",
    "    d = {dx: d[dx] for dx in d if d[dx].shape[0] != 0}\n",
    "    X = []\n",
    "    y = []\n",
    "    X1, y1, X2, y2, X3, y3, X4, y4 = [], [], [], [], [], [], [], []\n",
    "    for i in range(4):\n",
    "        tempX = []\n",
    "        tempy = []\n",
    "        for _, value in d.items():\n",
    "            row = value.iloc[[i]]\n",
    "            tempX.append(row.drop(['subject_id', 'visit', 'ScoreClass'], axis=1).values[0].astype(int))\n",
    "            tempy.append(int(row.ScoreClass))\n",
    "        X.append(tempX)\n",
    "        y.append(tempy)\n",
    "    X_new, y_new = prepare_dataset(X, y, x_ind, y_ind)\n",
    "    X_new_np = np.array(X_new)\n",
    "    y_new_np = np.array(y_new)\n",
    "    X_new_np += 1\n",
    "    print(X_new_np.shape)\n",
    "    print(y_new_np.shape)\n",
    "    X_csr = csr_matrix(X_new_np)\n",
    "    return X_csr, y_new_np\n",
    "\n",
    "def random_forest_training(X, y, S, filename):\n",
    "    os.system(filename)\n",
    "    for i in range(5):\n",
    "        logFile = open(filename + \"/\" + str(i) + \".txt\", \"w\")\n",
    "        X_tr, X_ts, y_tr, y_ts, S_tr, S_ts = splt(X, y, S, test_size=0.2, random_state=i, stratify = S)\n",
    "        rskf_ = rskf(n_splits=5, n_repeats=10, random_state=42)\n",
    "        counter = 0\n",
    "        for train_index, val_index in rskf_.split(X_tr, S_tr):\n",
    "            X_train, X_val = X_tr[train_index], X_tr[val_index]\n",
    "            y_train, y_val = y_tr[train_index], y_tr[val_index]\n",
    "            print(X_train.shape)\n",
    "            print(y_train.shape)\n",
    "            forest = rfc(n_estimators = 1000, max_depth = 100, n_jobs=-1)\n",
    "            forest.fit(X_train, y_train)\n",
    "            y_val_our = forest.predict(X_val)\n",
    "            mc = mcc(y_val, y_val_our)\n",
    "            ac = acc(y_val, y_val_our)\n",
    "            logFile.write('{} Split {} Iteration: MCC: {}, ACC: {}'.format(i, counter, mc, ac))\n",
    "            pickle.dump(forest, open(filename + \"/\" + str(i) + \"-\" + str(counter) + \"forest.pkl\", \"wb\"))\n",
    "            counter = counter + 1\n",
    "        forest = rfc(n_estimators = 1000, max_depth = 100)\n",
    "        forest.fit(X_tr, y_tr)\n",
    "        y_ts_our = forest.predict(X_ts)\n",
    "        mc = mcc(y_val, y_val_our)\n",
    "        ac = acc(y_val, y_val_our) \n",
    "        logFile.write('Final Iteration: MCC: {}, ACC: {}'.format(mc, ac))\n",
    "        pickle.dump(forest, open(filename + \"/final-forest.pkl\", \"wb\"))\n",
    "        mccCI = bootstrap_ci(np.array(dataMCC[i]))\n",
    "        accCI = bootstrap_ci(np.array(dataACC[i]))\n",
    "        logFile.write('MCC Interval: {} - {}'.format(mccCI[0], mccCI[1]))\n",
    "        logFile.write('ACC Interval: {} - {}'.format(accCI[0], accCI[1]))\n",
    "        logFile.close()\n",
    "\n",
    "def report_everything(csvFile, headers, x_ind, y_ind, filename):\n",
    "    df = pd.read_csv(csvFile)\n",
    "    df.sort_values(\"visit\")\n",
    "    df = df.select_dtypes(exclude=['object', 'datetime64'])\n",
    "    df = df.drop(labels = ['SCORE','ana_fis:smoking_recod', 'lab:glucose', 'lab:calculated_ldl', 'lab:total_cholesterol', 'ana:age'], axis=1)\n",
    "    df = df[df.columns[df.max() > 0]]\n",
    "    df.head()\n",
    "    groups = df.groupby([\"ScoreClass\", \"ana:gender\"])\n",
    "    X = df.values\n",
    "    print(X.shape)\n",
    "    S = np.zeros(X.shape[0])\n",
    "    for i, (_, dfGroup) in enumerate(groups):\n",
    "        indicies = dfGroup.index.values\n",
    "        S[indicies] = i\n",
    "    \n",
    "    X_, y_ = get_data_for_trial(df, headers, x_ind, y_ind)\n",
    "    random_forest_training(X_, y_, S, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5780, 181)\n",
      "(5780,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n",
      "(3696, 181)\n",
      "(3696,)\n",
      "(3697, 181)\n",
      "(3697,)\n",
      "(3698, 181)\n",
      "(3698,)\n",
      "(3701, 181)\n",
      "(3701,)\n",
      "(3704, 181)\n",
      "(3704,)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-0c94d1e830b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrandom_forest_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"total_lab-ult_tsa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#random_forest_training(X_2, y_2, \"total_lab\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#random_forest_training(X_3, y_3, \"total_ana_pat-ult_tsa\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-a7768e9bf2f5>\u001b[0m in \u001b[0;36mrandom_forest_training\u001b[0;34m(X, y, S, filename)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_our\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mlogFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final Iteration: MCC: {}, ACC: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/final-forest.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mmccCI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_ci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataMCC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0maccCI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_ci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataACC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "#X_1, y_1 = get_data_for_trial(df, [\"lab:\", \"ult_tsa:\"], [0, 1, 2, 3], [0, 1, 2, 3])\n",
    "#X_2, y_2 = get_data_for_trial(df, [\"lab:\"], [0, 1, 2, 3], [0, 1, 2, 3])\n",
    "#X_3, y_3 = get_data_for_trial(df, [\"ana_pat:\", \"ult_tsa:\"], [0, 1, 2, 3], [0, 1, 2, 3])\n",
    "#X_4, y_4 = get_data_for_trial(df, [\"ana_pat:\"], [0, 1, 2, 3], [0, 1, 2, 3])\n",
    "#X_5, y_5 = get_data_for_trial(df, [\"lab:\", \"ult_tsa:\", \"ana_pat\"], [0, 1, 2, 3], [0, 1, 2, 3])\n",
    "#random_forest_training(X_1, y_1, S, \"total_lab-ult_tsa\")\n",
    "#random_forest_training(X_2, y_2, \"total_lab\")\n",
    "#random_forest_training(X_3, y_3, \"total_ana_pat-ult_tsa\")\n",
    "#random_forest_training(X_4, y_4, \"total_ana_pat\")\n",
    "#random_forest_training(X_5, y_5, \"total_lab-ult_tsa-ana_pat\")\n",
    "report_everything(\"Data/new_wScore.csv\", [\"lab:\", \"ult_tsa:\"], [0, 1, 2, 3], [0, 1, 2, 3], \"total_lab-ult_tsa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:score] *",
   "language": "python",
   "name": "conda-env-score-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
