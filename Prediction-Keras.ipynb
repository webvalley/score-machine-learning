{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split as splt\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/new_wScore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"visit\")\n",
    "df = df.select_dtypes(exclude=['object', 'datetime64'])\n",
    "df = df.drop(labels = ['SCORE','ana_fis:smoking_recod', 'lab:glucose', 'lab:calculated_ldl', 'lab:total_cholesterol'], axis=1)\n",
    "df = df.fillna(-1).replace(-1, np.nan).replace(\"-1\", np.nan).replace(-1.0, np.nan)\n",
    "df = df.dropna(how='any', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {i: df.loc[df.subject_id == i, df.columns] for i in range(df.subject_id.iat[-1]+1)}\n",
    "d = {dx: d[dx] for dx in d if d[dx].shape[0] != 0}\n",
    "#X = np.array([np.array(values)[:-1,:-1] for key, values in d.items()])\n",
    "#X = np.array([X[:,:,i]/X[:,:,i].max() for i in range(X.shape[2])])\n",
    "#print(X.shape)\n",
    "#X = np.swapaxes(X, 0, 1)\n",
    "#X = np.swapaxes(X, 1, 2)\n",
    "#y = np.array([np.array(values)[-1,-1] for key, values in d.items()])\n",
    "#yy = np.zeros((y.shape[0], 4))\n",
    "#for i,yyy in enumerate(y):\n",
    "#    if(yyy < 0.01): # Low\n",
    "#       yy[i][0] = 1\n",
    "#    elif(yyy < 0.02): # Medium\n",
    "#        yy[i][1] = 1\n",
    "#    elif(yyy < 0.05): # High\n",
    "#        yy[i][2] = 1\n",
    "#    else: # Very High (aka Dead)\n",
    "#        yy[i][3] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = []\n",
    "y1 = []\n",
    "X2 = []\n",
    "y2 = []\n",
    "X3 = []\n",
    "y3 = []\n",
    "for key, value in d.items():\n",
    "    row1 = value.iloc[[0]]\n",
    "    row2 = value.iloc[[1]]\n",
    "    row3 = value.iloc[[2]]\n",
    "    row4 = value.iloc[[3]]\n",
    "    val = np.zeros(4)\n",
    "    val[row2.ScoreClass-1] = 1\n",
    "    y1.append(val)\n",
    "    X1.append(row1.drop('ScoreClass', axis=1).values[0])\n",
    "    \n",
    "    val = np.zeros(4)\n",
    "    val[row3.ScoreClass-1] = 1\n",
    "    y1.append(val)\n",
    "    X1.append(row2.drop('ScoreClass', axis=1).values[0])\n",
    "    \n",
    "    val = np.zeros(4)\n",
    "    val[row4.ScoreClass-1] = 1\n",
    "    y1.append(val)\n",
    "    X1.append(row3.drop('ScoreClass', axis=1).values[0])\n",
    "    \n",
    "    val = np.zeros(4)\n",
    "    val[row3.ScoreClass-1] = 1\n",
    "    y2.append(val)\n",
    "    X2.append(row1.drop('ScoreClass', axis=1).values[0])\n",
    "    \n",
    "    val = np.zeros(4)\n",
    "    val[row4.ScoreClass-1] = 1\n",
    "    y2.append(val)\n",
    "    X2.append(row2.drop('ScoreClass', axis=1).values[0])\n",
    "    \n",
    "    val = np.zeros(4)\n",
    "    val[row4.ScoreClass-1] = 1\n",
    "    y3.append(val)\n",
    "    X3.append(row1.drop('ScoreClass', axis=1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2)\n",
    "X3 = np.array(X3)\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "y3 = np.array(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(32, input_shape=(X1.shape[1], ), activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(8, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "model1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = splt(X1, y1, test_size=0.25, random_state=42)\n",
    "es = EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "history = model1.fit(X_tr, y_tr, validation_data=(X_ts, y_ts), epochs = 340)#, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts_pred = model1.predict(X_ts)\n",
    "cmatrix = np.zeros((4,4))\n",
    "for i,y_our in enumerate(y_ts_pred):\n",
    "    cmatrix[np.argmax(y_our)][np.argmax(y_ts[i])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cmatrix, index = [\"No\", \"Low\", \"Med\", \"High\"], columns = [\"No\", \"Low\", \"Med\", \"High\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "snheatmap = sn.heatmap(df_cm, annot=True,  fmt='g', cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(32, input_shape=(X2.shape[1], ), activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(16, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(4, activation='softmax'))\n",
    "model2.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = splt(X2, y2, test_size=0.25, random_state=42)\n",
    "es = EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "history = model2.fit(X_tr, y_tr, validation_data=(X_ts, y_ts), epochs = 340)#, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts_pred = model2.predict(X_ts)\n",
    "cmatrix = np.zeros((4,4))\n",
    "for i,y_our in enumerate(y_ts_pred):\n",
    "    cmatrix[np.argmax(y_our)][np.argmax(y_ts[i])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cmatrix, index = [\"No\", \"Low\", \"Med\", \"High\"], columns = [\"No\", \"Low\", \"Med\", \"High\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "snheatmap = sn.heatmap(df_cm, annot=True,  fmt='g', cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(32, input_shape=(X3.shape[1], ), activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(16, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(8, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(4, activation='softmax'))\n",
    "model3.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = splt(X3, y3, test_size=0.25, random_state=42)\n",
    "es = EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "history = model3.fit(X_tr, y_tr, validation_data=(X_ts, y_ts), epochs = 340)#, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ts_pred = model3.predict(X_ts)\n",
    "cmatrix = np.zeros((4,4))\n",
    "for i,y_our in enumerate(y_ts_pred):\n",
    "    cmatrix[np.argmax(y_our)][np.argmax(y_ts[i])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cmatrix, index = [\"No\", \"Low\", \"Med\", \"High\"], columns = [\"No\", \"Low\", \"Med\", \"High\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "snheatmap = sn.heatmap(df_cm, annot=True,  fmt='g', cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:score]",
   "language": "python",
   "name": "conda-env-score-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
