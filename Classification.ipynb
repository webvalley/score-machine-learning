{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split as splt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webvalley/anaconda3/envs/score/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (14,29,36,44,51,94,104,105,112,113,120,127,130,149,158,168,237,239,240,241,248,249,256,273,298) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dfy = pd.read_csv(\"MILANO_wSCORE.csv\")\n",
    "dfx = pd.read_csv(\"PLIC-milano-processed.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dfx.replace(-1, np.nan).replace(\"-1\", np.nan).replace(-1.0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dfx.loc[:, (dfx != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dfx.dropna(how='any', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfy['SCORE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx1 = dfx.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx1 = dfx1.drop(labels = ['smoking', 'smoking recod', 'glucose', 'Unnamed: 0', 'Unnamed: 0.1'], axis=1) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfx1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "bina = 0\n",
    "for i in range(X.shape[1]):\n",
    "    if (np.amax(X[:,i]) == 1):\n",
    "        bina += 1\n",
    "print(bina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/webvalley/anaconda3/envs/score/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/webvalley/anaconda3/envs/score/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X.shape[1], activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['angina', 'remote angina', 'antiaggregators', 'antidiabetics',\n",
       "       'antihypertensives', 'arteriopathyortic', 'remote arteriopathyortic',\n",
       "       'remote peripheral arteriopathy', 'COPD', 'bypass', 'remote bypass',\n",
       "       'CHD', 'Remote CHD', 'cod pcs', 'cholecystectomy',\n",
       "       'TORQUE AND ANGLE WRENCH', 'diabetes2 self', 'cerebral hemorrhage',\n",
       "       'hepatopathies NS', 'ages', 'NS Drugs', 'fibrates', 'fibrillationary',\n",
       "       'HDL', 'strokes', 'Remote stroke', 'IMA', 'Remote IMA',\n",
       "       'hypertension self', 'silent ischaemia', 'remote silent ischaemia',\n",
       "       'IVS', 'nephropathies NS', 'self obesity', 'PLACA',\n",
       "       'SECONDARY PREVENTION', 'PTCA', 'Remote PTCA', 'imbalance',\n",
       "       'remote decompensation', 'gender', 'statins', 'steatosis', 'TG', 'TIA',\n",
       "       'Remote TIA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                3008      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 5,220\n",
      "Trainable params: 5,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 0   0.04   0.12   0.24   1\n",
    "model.summary()\n",
    "X = X/X.max(axis=0)\n",
    "y = y/50\n",
    "yy = np.zeros((y.shape[0], 4))\n",
    "for i,yyy in enumerate(y):\n",
    "    if(yyy < 0.01): # Low\n",
    "        yy[i][0] = 1\n",
    "    elif(yyy < 0.02): # Medium\n",
    "        yy[i][1] = 1\n",
    "    elif(yyy < 0.05): # High\n",
    "        yy[i][2] = 1\n",
    "    else: # Very High (aka Dead)\n",
    "        yy[i][3] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9832266384694833\n"
     ]
    }
   ],
   "source": [
    "print(np.amax(X))\n",
    "print(np.amax(y))\n",
    "X_tr, X_ts, y_tr, y_ts = splt(X, yy, test_size=0.25, random_state=42)\n",
    "es = EarlyStopping(patience = 100, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/webvalley/anaconda3/envs/score/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4335 samples, validate on 1445 samples\n",
      "Epoch 1/2000\n",
      "4335/4335 [==============================] - 0s 64us/step - loss: 1.2718 - acc: 0.4491 - val_loss: 1.1990 - val_acc: 0.5024\n",
      "Epoch 2/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.2043 - acc: 0.4978 - val_loss: 1.1751 - val_acc: 0.5024\n",
      "Epoch 3/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.1802 - acc: 0.4999 - val_loss: 1.1412 - val_acc: 0.5024\n",
      "Epoch 4/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.1420 - acc: 0.5093 - val_loss: 1.0963 - val_acc: 0.5024\n",
      "Epoch 5/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.1163 - acc: 0.5299 - val_loss: 1.0651 - val_acc: 0.5599\n",
      "Epoch 6/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.0949 - acc: 0.5451 - val_loss: 1.0444 - val_acc: 0.5813\n",
      "Epoch 7/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.0701 - acc: 0.5516 - val_loss: 1.0292 - val_acc: 0.5765\n",
      "Epoch 8/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.0577 - acc: 0.5642 - val_loss: 1.0186 - val_acc: 0.5765\n",
      "Epoch 9/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.0475 - acc: 0.5649 - val_loss: 1.0050 - val_acc: 0.5744\n",
      "Epoch 10/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.0343 - acc: 0.5735 - val_loss: 0.9955 - val_acc: 0.5855\n",
      "Epoch 11/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.0319 - acc: 0.5725 - val_loss: 0.9867 - val_acc: 0.5765\n",
      "Epoch 12/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.0220 - acc: 0.5712 - val_loss: 0.9780 - val_acc: 0.5744\n",
      "Epoch 13/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.0078 - acc: 0.5829 - val_loss: 0.9683 - val_acc: 0.5758\n",
      "Epoch 14/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 1.0064 - acc: 0.5857 - val_loss: 0.9597 - val_acc: 0.5779\n",
      "Epoch 15/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.9890 - acc: 0.5869 - val_loss: 0.9505 - val_acc: 0.5875\n",
      "Epoch 16/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.9834 - acc: 0.5938 - val_loss: 0.9392 - val_acc: 0.5862\n",
      "Epoch 17/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.9742 - acc: 0.5928 - val_loss: 0.9302 - val_acc: 0.5889\n",
      "Epoch 18/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.9734 - acc: 0.5977 - val_loss: 0.9191 - val_acc: 0.5903\n",
      "Epoch 19/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.9559 - acc: 0.5982 - val_loss: 0.9105 - val_acc: 0.6028\n",
      "Epoch 20/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.9494 - acc: 0.5995 - val_loss: 0.8976 - val_acc: 0.6083\n",
      "Epoch 21/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.9435 - acc: 0.6048 - val_loss: 0.8875 - val_acc: 0.6159\n",
      "Epoch 22/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.9287 - acc: 0.6081 - val_loss: 0.8918 - val_acc: 0.6457\n",
      "Epoch 23/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.9230 - acc: 0.6104 - val_loss: 0.8643 - val_acc: 0.6332\n",
      "Epoch 24/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.9083 - acc: 0.6249 - val_loss: 0.8557 - val_acc: 0.6284\n",
      "Epoch 25/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.8987 - acc: 0.6265 - val_loss: 0.8402 - val_acc: 0.6512\n",
      "Epoch 26/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8944 - acc: 0.6178 - val_loss: 0.8299 - val_acc: 0.6429\n",
      "Epoch 27/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8904 - acc: 0.6277 - val_loss: 0.8173 - val_acc: 0.6602\n",
      "Epoch 28/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8695 - acc: 0.6334 - val_loss: 0.8064 - val_acc: 0.6671\n",
      "Epoch 29/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8599 - acc: 0.6388 - val_loss: 0.7940 - val_acc: 0.6747\n",
      "Epoch 30/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8631 - acc: 0.6381 - val_loss: 0.7841 - val_acc: 0.6768\n",
      "Epoch 31/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8401 - acc: 0.6443 - val_loss: 0.7721 - val_acc: 0.6782\n",
      "Epoch 32/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8442 - acc: 0.6484 - val_loss: 0.7630 - val_acc: 0.6851\n",
      "Epoch 33/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8359 - acc: 0.6454 - val_loss: 0.7552 - val_acc: 0.6955\n",
      "Epoch 34/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8292 - acc: 0.6512 - val_loss: 0.7461 - val_acc: 0.6948\n",
      "Epoch 35/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8161 - acc: 0.6581 - val_loss: 0.7386 - val_acc: 0.7100\n",
      "Epoch 36/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8110 - acc: 0.6567 - val_loss: 0.7305 - val_acc: 0.7107\n",
      "Epoch 37/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8056 - acc: 0.6563 - val_loss: 0.7223 - val_acc: 0.7073\n",
      "Epoch 38/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.8033 - acc: 0.6593 - val_loss: 0.7164 - val_acc: 0.7038\n",
      "Epoch 39/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7942 - acc: 0.6630 - val_loss: 0.7091 - val_acc: 0.7107\n",
      "Epoch 40/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7886 - acc: 0.6694 - val_loss: 0.7033 - val_acc: 0.7266\n",
      "Epoch 41/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7836 - acc: 0.6671 - val_loss: 0.6988 - val_acc: 0.7301\n",
      "Epoch 42/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7734 - acc: 0.6681 - val_loss: 0.6890 - val_acc: 0.7176\n",
      "Epoch 43/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.7631 - acc: 0.6791 - val_loss: 0.6822 - val_acc: 0.7253\n",
      "Epoch 44/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7546 - acc: 0.6821 - val_loss: 0.6744 - val_acc: 0.7294\n",
      "Epoch 45/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7680 - acc: 0.6708 - val_loss: 0.6726 - val_acc: 0.7176\n",
      "Epoch 46/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.7475 - acc: 0.6867 - val_loss: 0.6666 - val_acc: 0.7398\n",
      "Epoch 47/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7472 - acc: 0.6807 - val_loss: 0.6685 - val_acc: 0.7474\n",
      "Epoch 48/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7445 - acc: 0.6754 - val_loss: 0.6539 - val_acc: 0.7349\n",
      "Epoch 49/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7338 - acc: 0.6817 - val_loss: 0.6490 - val_acc: 0.7439\n",
      "Epoch 50/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7478 - acc: 0.6805 - val_loss: 0.6479 - val_acc: 0.7509\n",
      "Epoch 51/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7277 - acc: 0.6840 - val_loss: 0.6439 - val_acc: 0.7522\n",
      "Epoch 52/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.7155 - acc: 0.6957 - val_loss: 0.6386 - val_acc: 0.7481\n",
      "Epoch 53/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7311 - acc: 0.6844 - val_loss: 0.6349 - val_acc: 0.7363\n",
      "Epoch 54/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7149 - acc: 0.6990 - val_loss: 0.6391 - val_acc: 0.7308\n",
      "Epoch 55/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7144 - acc: 0.7001 - val_loss: 0.6268 - val_acc: 0.7509\n",
      "Epoch 56/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7242 - acc: 0.6856 - val_loss: 0.6254 - val_acc: 0.7522\n",
      "Epoch 57/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6947 - acc: 0.6969 - val_loss: 0.6220 - val_acc: 0.7446\n",
      "Epoch 58/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7099 - acc: 0.6946 - val_loss: 0.6182 - val_acc: 0.7599\n",
      "Epoch 59/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7029 - acc: 0.6971 - val_loss: 0.6158 - val_acc: 0.7578\n",
      "Epoch 60/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7098 - acc: 0.6916 - val_loss: 0.6145 - val_acc: 0.7495\n",
      "Epoch 61/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7029 - acc: 0.7006 - val_loss: 0.6088 - val_acc: 0.7626\n",
      "Epoch 62/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6980 - acc: 0.7003 - val_loss: 0.6106 - val_acc: 0.7606\n",
      "Epoch 63/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.7030 - acc: 0.7001 - val_loss: 0.6082 - val_acc: 0.7668\n",
      "Epoch 64/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6907 - acc: 0.6971 - val_loss: 0.6082 - val_acc: 0.7481\n",
      "Epoch 65/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6899 - acc: 0.7022 - val_loss: 0.6002 - val_acc: 0.7578\n",
      "Epoch 66/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6973 - acc: 0.6953 - val_loss: 0.5987 - val_acc: 0.7557\n",
      "Epoch 67/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6979 - acc: 0.6948 - val_loss: 0.5993 - val_acc: 0.7536\n",
      "Epoch 68/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6744 - acc: 0.7036 - val_loss: 0.5952 - val_acc: 0.7557\n",
      "Epoch 69/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6803 - acc: 0.7093 - val_loss: 0.5962 - val_acc: 0.7536\n",
      "Epoch 70/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6945 - acc: 0.7001 - val_loss: 0.5931 - val_acc: 0.7640\n",
      "Epoch 71/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6805 - acc: 0.7121 - val_loss: 0.5935 - val_acc: 0.7730\n",
      "Epoch 72/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6735 - acc: 0.7015 - val_loss: 0.5869 - val_acc: 0.7675\n",
      "Epoch 73/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6768 - acc: 0.7054 - val_loss: 0.5864 - val_acc: 0.7661\n",
      "Epoch 74/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6725 - acc: 0.7075 - val_loss: 0.5871 - val_acc: 0.7709\n",
      "Epoch 75/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6737 - acc: 0.7040 - val_loss: 0.5872 - val_acc: 0.7702\n",
      "Epoch 76/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6601 - acc: 0.7075 - val_loss: 0.5829 - val_acc: 0.7599\n",
      "Epoch 77/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6603 - acc: 0.7114 - val_loss: 0.5814 - val_acc: 0.7612\n",
      "Epoch 78/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6653 - acc: 0.7135 - val_loss: 0.5801 - val_acc: 0.7647\n",
      "Epoch 79/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6660 - acc: 0.7123 - val_loss: 0.5784 - val_acc: 0.7730\n",
      "Epoch 80/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6661 - acc: 0.7040 - val_loss: 0.5745 - val_acc: 0.7744\n",
      "Epoch 81/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6672 - acc: 0.7052 - val_loss: 0.5762 - val_acc: 0.7612\n",
      "Epoch 82/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6559 - acc: 0.7209 - val_loss: 0.5740 - val_acc: 0.7606\n",
      "Epoch 83/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6535 - acc: 0.7105 - val_loss: 0.5728 - val_acc: 0.7744\n",
      "Epoch 84/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.6757 - acc: 0.7059 - val_loss: 0.5691 - val_acc: 0.7758\n",
      "Epoch 85/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6417 - acc: 0.7144 - val_loss: 0.5703 - val_acc: 0.7702\n",
      "Epoch 86/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6434 - acc: 0.7216 - val_loss: 0.5652 - val_acc: 0.7689\n",
      "Epoch 87/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6585 - acc: 0.7160 - val_loss: 0.5703 - val_acc: 0.7557\n",
      "Epoch 88/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6560 - acc: 0.7144 - val_loss: 0.5666 - val_acc: 0.7765\n",
      "Epoch 89/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6406 - acc: 0.7239 - val_loss: 0.5623 - val_acc: 0.7709\n",
      "Epoch 90/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6378 - acc: 0.7220 - val_loss: 0.5755 - val_acc: 0.7495\n",
      "Epoch 91/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6429 - acc: 0.7195 - val_loss: 0.5593 - val_acc: 0.7689\n",
      "Epoch 92/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6405 - acc: 0.7197 - val_loss: 0.5578 - val_acc: 0.7765\n",
      "Epoch 93/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6414 - acc: 0.7163 - val_loss: 0.5570 - val_acc: 0.7758\n",
      "Epoch 94/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6355 - acc: 0.7151 - val_loss: 0.5569 - val_acc: 0.7709\n",
      "Epoch 95/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6364 - acc: 0.7216 - val_loss: 0.5542 - val_acc: 0.7730\n",
      "Epoch 96/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.6390 - acc: 0.7156 - val_loss: 0.5540 - val_acc: 0.7716\n",
      "Epoch 97/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6351 - acc: 0.7266 - val_loss: 0.5533 - val_acc: 0.7751\n",
      "Epoch 98/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6195 - acc: 0.7193 - val_loss: 0.5512 - val_acc: 0.7806\n",
      "Epoch 99/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6337 - acc: 0.7202 - val_loss: 0.5504 - val_acc: 0.7758\n",
      "Epoch 100/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6241 - acc: 0.7283 - val_loss: 0.5488 - val_acc: 0.7737\n",
      "Epoch 101/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6283 - acc: 0.7264 - val_loss: 0.5621 - val_acc: 0.7550\n",
      "Epoch 102/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6401 - acc: 0.7225 - val_loss: 0.5480 - val_acc: 0.7869\n",
      "Epoch 103/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6236 - acc: 0.7243 - val_loss: 0.5521 - val_acc: 0.7654\n",
      "Epoch 104/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6133 - acc: 0.7243 - val_loss: 0.5481 - val_acc: 0.7855\n",
      "Epoch 105/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6246 - acc: 0.7278 - val_loss: 0.5462 - val_acc: 0.7848\n",
      "Epoch 106/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6302 - acc: 0.7241 - val_loss: 0.5466 - val_acc: 0.7709\n",
      "Epoch 107/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6203 - acc: 0.7287 - val_loss: 0.5451 - val_acc: 0.7799\n",
      "Epoch 108/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6185 - acc: 0.7326 - val_loss: 0.5485 - val_acc: 0.7875\n",
      "Epoch 109/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6222 - acc: 0.7273 - val_loss: 0.5469 - val_acc: 0.7779\n",
      "Epoch 110/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6209 - acc: 0.7190 - val_loss: 0.5425 - val_acc: 0.7813\n",
      "Epoch 111/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6135 - acc: 0.7315 - val_loss: 0.5437 - val_acc: 0.7813\n",
      "Epoch 112/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6216 - acc: 0.7285 - val_loss: 0.5401 - val_acc: 0.7848\n",
      "Epoch 113/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.6049 - acc: 0.7407 - val_loss: 0.5417 - val_acc: 0.7882\n",
      "Epoch 114/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6088 - acc: 0.7336 - val_loss: 0.5463 - val_acc: 0.7709\n",
      "Epoch 115/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6094 - acc: 0.7317 - val_loss: 0.5432 - val_acc: 0.7772\n",
      "Epoch 116/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6246 - acc: 0.7218 - val_loss: 0.5425 - val_acc: 0.7758\n",
      "Epoch 117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6087 - acc: 0.7373 - val_loss: 0.5368 - val_acc: 0.7785\n",
      "Epoch 118/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6151 - acc: 0.7287 - val_loss: 0.5374 - val_acc: 0.7869\n",
      "Epoch 119/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.6117 - acc: 0.7354 - val_loss: 0.5363 - val_acc: 0.7931\n",
      "Epoch 120/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6066 - acc: 0.7336 - val_loss: 0.5379 - val_acc: 0.7903\n",
      "Epoch 121/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6062 - acc: 0.7343 - val_loss: 0.5362 - val_acc: 0.7848\n",
      "Epoch 122/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6171 - acc: 0.7206 - val_loss: 0.5349 - val_acc: 0.7862\n",
      "Epoch 123/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6139 - acc: 0.7273 - val_loss: 0.5356 - val_acc: 0.7806\n",
      "Epoch 124/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6104 - acc: 0.7338 - val_loss: 0.5379 - val_acc: 0.7806\n",
      "Epoch 125/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6052 - acc: 0.7262 - val_loss: 0.5357 - val_acc: 0.7834\n",
      "Epoch 126/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6141 - acc: 0.7354 - val_loss: 0.5362 - val_acc: 0.7889\n",
      "Epoch 127/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6100 - acc: 0.7398 - val_loss: 0.5339 - val_acc: 0.7917\n",
      "Epoch 128/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5973 - acc: 0.7391 - val_loss: 0.5328 - val_acc: 0.7952\n",
      "Epoch 129/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.6110 - acc: 0.7354 - val_loss: 0.5333 - val_acc: 0.7848\n",
      "Epoch 130/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6003 - acc: 0.7338 - val_loss: 0.5309 - val_acc: 0.7903\n",
      "Epoch 131/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6002 - acc: 0.7315 - val_loss: 0.5319 - val_acc: 0.7806\n",
      "Epoch 132/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5964 - acc: 0.7407 - val_loss: 0.5315 - val_acc: 0.7855\n",
      "Epoch 133/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.6068 - acc: 0.7310 - val_loss: 0.5303 - val_acc: 0.7869\n",
      "Epoch 134/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5938 - acc: 0.7359 - val_loss: 0.5276 - val_acc: 0.7945\n",
      "Epoch 135/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6001 - acc: 0.7338 - val_loss: 0.5275 - val_acc: 0.7945\n",
      "Epoch 136/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6040 - acc: 0.7296 - val_loss: 0.5312 - val_acc: 0.7945\n",
      "Epoch 137/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.6006 - acc: 0.7375 - val_loss: 0.5303 - val_acc: 0.7903\n",
      "Epoch 138/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5963 - acc: 0.7405 - val_loss: 0.5271 - val_acc: 0.7931\n",
      "Epoch 139/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5968 - acc: 0.7336 - val_loss: 0.5278 - val_acc: 0.7903\n",
      "Epoch 140/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5882 - acc: 0.7430 - val_loss: 0.5276 - val_acc: 0.7875\n",
      "Epoch 141/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5869 - acc: 0.7405 - val_loss: 0.5292 - val_acc: 0.7813\n",
      "Epoch 142/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5965 - acc: 0.7382 - val_loss: 0.5239 - val_acc: 0.7889\n",
      "Epoch 143/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5859 - acc: 0.7368 - val_loss: 0.5286 - val_acc: 0.7799\n",
      "Epoch 144/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5849 - acc: 0.7437 - val_loss: 0.5229 - val_acc: 0.7910\n",
      "Epoch 145/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5878 - acc: 0.7449 - val_loss: 0.5245 - val_acc: 0.7889\n",
      "Epoch 146/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.6078 - acc: 0.7354 - val_loss: 0.5251 - val_acc: 0.7875\n",
      "Epoch 147/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.5880 - acc: 0.7393 - val_loss: 0.5246 - val_acc: 0.7931\n",
      "Epoch 148/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.5868 - acc: 0.7458 - val_loss: 0.5221 - val_acc: 0.7910\n",
      "Epoch 149/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.5965 - acc: 0.7324 - val_loss: 0.5305 - val_acc: 0.7820\n",
      "Epoch 150/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.5905 - acc: 0.7398 - val_loss: 0.5244 - val_acc: 0.7924\n",
      "Epoch 151/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5933 - acc: 0.7407 - val_loss: 0.5264 - val_acc: 0.7820\n",
      "Epoch 152/2000\n",
      "4335/4335 [==============================] - 0s 28us/step - loss: 0.5838 - acc: 0.7453 - val_loss: 0.5240 - val_acc: 0.7862\n",
      "Epoch 153/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.5791 - acc: 0.7483 - val_loss: 0.5225 - val_acc: 0.7945\n",
      "Epoch 154/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.5853 - acc: 0.7463 - val_loss: 0.5221 - val_acc: 0.7910\n",
      "Epoch 155/2000\n",
      "4335/4335 [==============================] - 0s 28us/step - loss: 0.5834 - acc: 0.7483 - val_loss: 0.5210 - val_acc: 0.7924\n",
      "Epoch 156/2000\n",
      "4335/4335 [==============================] - 0s 30us/step - loss: 0.5795 - acc: 0.7437 - val_loss: 0.5214 - val_acc: 0.7903\n",
      "Epoch 157/2000\n",
      "4335/4335 [==============================] - 0s 29us/step - loss: 0.5886 - acc: 0.7428 - val_loss: 0.5255 - val_acc: 0.7806\n",
      "Epoch 158/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.5937 - acc: 0.7405 - val_loss: 0.5207 - val_acc: 0.7945\n",
      "Epoch 159/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.5941 - acc: 0.7444 - val_loss: 0.5200 - val_acc: 0.7952\n",
      "Epoch 160/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5835 - acc: 0.7426 - val_loss: 0.5217 - val_acc: 0.7924\n",
      "Epoch 161/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5909 - acc: 0.7396 - val_loss: 0.5203 - val_acc: 0.7931\n",
      "Epoch 162/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5859 - acc: 0.7409 - val_loss: 0.5195 - val_acc: 0.7931\n",
      "Epoch 163/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5933 - acc: 0.7407 - val_loss: 0.5208 - val_acc: 0.7841\n",
      "Epoch 164/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5776 - acc: 0.7479 - val_loss: 0.5183 - val_acc: 0.7952\n",
      "Epoch 165/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5809 - acc: 0.7414 - val_loss: 0.5176 - val_acc: 0.7958\n",
      "Epoch 166/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5933 - acc: 0.7393 - val_loss: 0.5182 - val_acc: 0.7938\n",
      "Epoch 167/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5864 - acc: 0.7474 - val_loss: 0.5176 - val_acc: 0.7979\n",
      "Epoch 168/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5813 - acc: 0.7412 - val_loss: 0.5190 - val_acc: 0.7938\n",
      "Epoch 169/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5820 - acc: 0.7405 - val_loss: 0.5183 - val_acc: 0.7910\n",
      "Epoch 170/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5914 - acc: 0.7393 - val_loss: 0.5194 - val_acc: 0.7862\n",
      "Epoch 171/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5691 - acc: 0.7456 - val_loss: 0.5171 - val_acc: 0.7958\n",
      "Epoch 172/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5798 - acc: 0.7474 - val_loss: 0.5195 - val_acc: 0.7827\n",
      "Epoch 173/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5856 - acc: 0.7368 - val_loss: 0.5167 - val_acc: 0.7938\n",
      "Epoch 174/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5645 - acc: 0.7469 - val_loss: 0.5163 - val_acc: 0.7965\n",
      "Epoch 175/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5947 - acc: 0.7428 - val_loss: 0.5200 - val_acc: 0.7862\n",
      "Epoch 176/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5799 - acc: 0.7486 - val_loss: 0.5152 - val_acc: 0.7924\n",
      "Epoch 177/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5760 - acc: 0.7439 - val_loss: 0.5170 - val_acc: 0.7931\n",
      "Epoch 178/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5621 - acc: 0.7456 - val_loss: 0.5181 - val_acc: 0.7834\n",
      "Epoch 179/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5828 - acc: 0.7456 - val_loss: 0.5164 - val_acc: 0.7903\n",
      "Epoch 180/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5738 - acc: 0.7479 - val_loss: 0.5143 - val_acc: 0.7924\n",
      "Epoch 181/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5683 - acc: 0.7481 - val_loss: 0.5175 - val_acc: 0.7855\n",
      "Epoch 182/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5700 - acc: 0.7486 - val_loss: 0.5134 - val_acc: 0.7910\n",
      "Epoch 183/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5709 - acc: 0.7426 - val_loss: 0.5134 - val_acc: 0.7903\n",
      "Epoch 184/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5668 - acc: 0.7451 - val_loss: 0.5256 - val_acc: 0.7730\n",
      "Epoch 185/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5694 - acc: 0.7490 - val_loss: 0.5126 - val_acc: 0.7903\n",
      "Epoch 186/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5682 - acc: 0.7476 - val_loss: 0.5109 - val_acc: 0.7917\n",
      "Epoch 187/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5767 - acc: 0.7403 - val_loss: 0.5134 - val_acc: 0.7896\n",
      "Epoch 188/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5726 - acc: 0.7439 - val_loss: 0.5117 - val_acc: 0.7945\n",
      "Epoch 189/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5571 - acc: 0.7571 - val_loss: 0.5125 - val_acc: 0.7945\n",
      "Epoch 190/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5622 - acc: 0.7559 - val_loss: 0.5125 - val_acc: 0.7855\n",
      "Epoch 191/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5685 - acc: 0.7456 - val_loss: 0.5106 - val_acc: 0.7945\n",
      "Epoch 192/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5603 - acc: 0.7642 - val_loss: 0.5103 - val_acc: 0.7958\n",
      "Epoch 193/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5665 - acc: 0.7527 - val_loss: 0.5165 - val_acc: 0.7841\n",
      "Epoch 194/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5707 - acc: 0.7481 - val_loss: 0.5100 - val_acc: 0.7965\n",
      "Epoch 195/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5685 - acc: 0.7465 - val_loss: 0.5108 - val_acc: 0.7952\n",
      "Epoch 196/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5689 - acc: 0.7476 - val_loss: 0.5095 - val_acc: 0.7938\n",
      "Epoch 197/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5657 - acc: 0.7502 - val_loss: 0.5124 - val_acc: 0.7882\n",
      "Epoch 198/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5548 - acc: 0.7550 - val_loss: 0.5205 - val_acc: 0.7779\n",
      "Epoch 199/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5627 - acc: 0.7516 - val_loss: 0.5106 - val_acc: 0.7952\n",
      "Epoch 200/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5668 - acc: 0.7569 - val_loss: 0.5144 - val_acc: 0.7834\n",
      "Epoch 201/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5611 - acc: 0.7536 - val_loss: 0.5092 - val_acc: 0.7945\n",
      "Epoch 202/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5654 - acc: 0.7562 - val_loss: 0.5113 - val_acc: 0.7799\n",
      "Epoch 203/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5561 - acc: 0.7571 - val_loss: 0.5113 - val_acc: 0.7903\n",
      "Epoch 204/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5672 - acc: 0.7488 - val_loss: 0.5072 - val_acc: 0.7986\n",
      "Epoch 205/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5627 - acc: 0.7522 - val_loss: 0.5120 - val_acc: 0.7862\n",
      "Epoch 206/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5599 - acc: 0.7543 - val_loss: 0.5119 - val_acc: 0.7875\n",
      "Epoch 207/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5585 - acc: 0.7534 - val_loss: 0.5071 - val_acc: 0.7972\n",
      "Epoch 208/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5564 - acc: 0.7506 - val_loss: 0.5111 - val_acc: 0.7910\n",
      "Epoch 209/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5529 - acc: 0.7562 - val_loss: 0.5086 - val_acc: 0.7958\n",
      "Epoch 210/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5613 - acc: 0.7412 - val_loss: 0.5088 - val_acc: 0.7889\n",
      "Epoch 211/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5572 - acc: 0.7499 - val_loss: 0.5088 - val_acc: 0.7875\n",
      "Epoch 212/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5640 - acc: 0.7476 - val_loss: 0.5072 - val_acc: 0.7896\n",
      "Epoch 213/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5561 - acc: 0.7589 - val_loss: 0.5087 - val_acc: 0.7896\n",
      "Epoch 214/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5641 - acc: 0.7502 - val_loss: 0.5060 - val_acc: 0.7938\n",
      "Epoch 215/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5560 - acc: 0.7555 - val_loss: 0.5079 - val_acc: 0.7896\n",
      "Epoch 216/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5576 - acc: 0.7580 - val_loss: 0.5114 - val_acc: 0.7896\n",
      "Epoch 217/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5599 - acc: 0.7502 - val_loss: 0.5060 - val_acc: 0.7917\n",
      "Epoch 218/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5542 - acc: 0.7555 - val_loss: 0.5065 - val_acc: 0.7896\n",
      "Epoch 219/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5539 - acc: 0.7486 - val_loss: 0.5052 - val_acc: 0.7938\n",
      "Epoch 220/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5574 - acc: 0.7564 - val_loss: 0.5052 - val_acc: 0.7945\n",
      "Epoch 221/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5536 - acc: 0.7564 - val_loss: 0.5094 - val_acc: 0.7875\n",
      "Epoch 222/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5498 - acc: 0.7525 - val_loss: 0.5084 - val_acc: 0.7875\n",
      "Epoch 223/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5591 - acc: 0.7518 - val_loss: 0.5039 - val_acc: 0.7972\n",
      "Epoch 224/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5582 - acc: 0.7536 - val_loss: 0.5061 - val_acc: 0.7945\n",
      "Epoch 225/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5536 - acc: 0.7564 - val_loss: 0.5064 - val_acc: 0.7903\n",
      "Epoch 226/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5538 - acc: 0.7506 - val_loss: 0.5086 - val_acc: 0.7903\n",
      "Epoch 227/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5520 - acc: 0.7580 - val_loss: 0.5053 - val_acc: 0.7945\n",
      "Epoch 228/2000\n",
      "4335/4335 [==============================] - 0s 21us/step - loss: 0.5571 - acc: 0.7493 - val_loss: 0.5046 - val_acc: 0.7896\n",
      "Epoch 229/2000\n",
      "4335/4335 [==============================] - 0s 21us/step - loss: 0.5609 - acc: 0.7543 - val_loss: 0.5053 - val_acc: 0.7958\n",
      "Epoch 230/2000\n",
      "4335/4335 [==============================] - 0s 21us/step - loss: 0.5540 - acc: 0.7495 - val_loss: 0.5099 - val_acc: 0.7799\n",
      "Epoch 231/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5470 - acc: 0.7559 - val_loss: 0.5042 - val_acc: 0.7903\n",
      "Epoch 232/2000\n",
      "4335/4335 [==============================] - 0s 21us/step - loss: 0.5520 - acc: 0.7502 - val_loss: 0.5042 - val_acc: 0.7965\n",
      "Epoch 233/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5514 - acc: 0.7557 - val_loss: 0.5041 - val_acc: 0.7924\n",
      "Epoch 234/2000\n",
      "4335/4335 [==============================] - 0s 21us/step - loss: 0.5455 - acc: 0.7529 - val_loss: 0.5031 - val_acc: 0.7924\n",
      "Epoch 235/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5532 - acc: 0.7610 - val_loss: 0.5040 - val_acc: 0.7875\n",
      "Epoch 236/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5533 - acc: 0.7493 - val_loss: 0.5039 - val_acc: 0.7952\n",
      "Epoch 237/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5517 - acc: 0.7509 - val_loss: 0.5053 - val_acc: 0.7848\n",
      "Epoch 238/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5507 - acc: 0.7550 - val_loss: 0.5071 - val_acc: 0.7917\n",
      "Epoch 239/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5472 - acc: 0.7608 - val_loss: 0.5044 - val_acc: 0.7910\n",
      "Epoch 240/2000\n",
      "4335/4335 [==============================] - 0s 21us/step - loss: 0.5510 - acc: 0.7585 - val_loss: 0.5018 - val_acc: 0.7938\n",
      "Epoch 241/2000\n",
      "4335/4335 [==============================] - 0s 21us/step - loss: 0.5550 - acc: 0.7589 - val_loss: 0.5062 - val_acc: 0.7889\n",
      "Epoch 242/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5536 - acc: 0.7525 - val_loss: 0.5058 - val_acc: 0.7938\n",
      "Epoch 243/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5561 - acc: 0.7569 - val_loss: 0.5044 - val_acc: 0.7924\n",
      "Epoch 244/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5570 - acc: 0.7550 - val_loss: 0.5034 - val_acc: 0.7945\n",
      "Epoch 245/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5450 - acc: 0.7481 - val_loss: 0.5054 - val_acc: 0.7924\n",
      "Epoch 246/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5460 - acc: 0.7606 - val_loss: 0.5022 - val_acc: 0.7924\n",
      "Epoch 247/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5417 - acc: 0.7550 - val_loss: 0.5045 - val_acc: 0.7931\n",
      "Epoch 248/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5510 - acc: 0.7559 - val_loss: 0.5040 - val_acc: 0.7931\n",
      "Epoch 249/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5520 - acc: 0.7569 - val_loss: 0.5024 - val_acc: 0.7938\n",
      "Epoch 250/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5449 - acc: 0.7576 - val_loss: 0.5030 - val_acc: 0.7945\n",
      "Epoch 251/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5428 - acc: 0.7548 - val_loss: 0.5065 - val_acc: 0.7841\n",
      "Epoch 252/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5501 - acc: 0.7536 - val_loss: 0.5086 - val_acc: 0.7889\n",
      "Epoch 253/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5480 - acc: 0.7592 - val_loss: 0.5050 - val_acc: 0.7931\n",
      "Epoch 254/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5483 - acc: 0.7610 - val_loss: 0.5025 - val_acc: 0.7917\n",
      "Epoch 255/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5493 - acc: 0.7511 - val_loss: 0.5048 - val_acc: 0.7945\n",
      "Epoch 256/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5505 - acc: 0.7645 - val_loss: 0.5024 - val_acc: 0.7945\n",
      "Epoch 257/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5431 - acc: 0.7601 - val_loss: 0.5058 - val_acc: 0.7855\n",
      "Epoch 258/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5375 - acc: 0.7610 - val_loss: 0.5013 - val_acc: 0.7958\n",
      "Epoch 259/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5385 - acc: 0.7601 - val_loss: 0.5017 - val_acc: 0.7958\n",
      "Epoch 260/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5391 - acc: 0.7640 - val_loss: 0.5008 - val_acc: 0.7931\n",
      "Epoch 261/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5446 - acc: 0.7587 - val_loss: 0.5018 - val_acc: 0.7979\n",
      "Epoch 262/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5429 - acc: 0.7580 - val_loss: 0.5012 - val_acc: 0.7972\n",
      "Epoch 263/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5504 - acc: 0.7552 - val_loss: 0.5006 - val_acc: 0.7869\n",
      "Epoch 264/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5461 - acc: 0.7580 - val_loss: 0.4996 - val_acc: 0.7931\n",
      "Epoch 265/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5530 - acc: 0.7527 - val_loss: 0.5019 - val_acc: 0.7972\n",
      "Epoch 266/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.5482 - acc: 0.7529 - val_loss: 0.5056 - val_acc: 0.7882\n",
      "Epoch 267/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.5388 - acc: 0.7622 - val_loss: 0.5000 - val_acc: 0.7979\n",
      "Epoch 268/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.5449 - acc: 0.7550 - val_loss: 0.5010 - val_acc: 0.7889\n",
      "Epoch 269/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.5404 - acc: 0.7677 - val_loss: 0.5057 - val_acc: 0.7882\n",
      "Epoch 270/2000\n",
      "4335/4335 [==============================] - 0s 29us/step - loss: 0.5419 - acc: 0.7682 - val_loss: 0.5015 - val_acc: 0.7924\n",
      "Epoch 271/2000\n",
      "4335/4335 [==============================] - 0s 29us/step - loss: 0.5469 - acc: 0.7580 - val_loss: 0.5008 - val_acc: 0.7938\n",
      "Epoch 272/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5440 - acc: 0.7573 - val_loss: 0.4995 - val_acc: 0.7875\n",
      "Epoch 273/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5424 - acc: 0.7610 - val_loss: 0.5024 - val_acc: 0.7917\n",
      "Epoch 274/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5472 - acc: 0.7527 - val_loss: 0.4998 - val_acc: 0.7924\n",
      "Epoch 275/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5364 - acc: 0.7603 - val_loss: 0.5048 - val_acc: 0.7875\n",
      "Epoch 276/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5446 - acc: 0.7541 - val_loss: 0.5000 - val_acc: 0.7896\n",
      "Epoch 277/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5397 - acc: 0.7631 - val_loss: 0.5054 - val_acc: 0.7875\n",
      "Epoch 278/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.5482 - acc: 0.7578 - val_loss: 0.5007 - val_acc: 0.7945\n",
      "Epoch 279/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5339 - acc: 0.7652 - val_loss: 0.4997 - val_acc: 0.7896\n",
      "Epoch 280/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5412 - acc: 0.7636 - val_loss: 0.5001 - val_acc: 0.7958\n",
      "Epoch 281/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5313 - acc: 0.7578 - val_loss: 0.4998 - val_acc: 0.7910\n",
      "Epoch 282/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5323 - acc: 0.7631 - val_loss: 0.4979 - val_acc: 0.7896\n",
      "Epoch 283/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5404 - acc: 0.7659 - val_loss: 0.4980 - val_acc: 0.7952\n",
      "Epoch 284/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5374 - acc: 0.7557 - val_loss: 0.4971 - val_acc: 0.7938\n",
      "Epoch 285/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5453 - acc: 0.7550 - val_loss: 0.4992 - val_acc: 0.7952\n",
      "Epoch 286/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.5278 - acc: 0.7585 - val_loss: 0.4999 - val_acc: 0.7896\n",
      "Epoch 287/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5312 - acc: 0.7633 - val_loss: 0.4989 - val_acc: 0.7924\n",
      "Epoch 288/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5428 - acc: 0.7564 - val_loss: 0.4994 - val_acc: 0.7903\n",
      "Epoch 289/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5239 - acc: 0.7626 - val_loss: 0.4987 - val_acc: 0.7903\n",
      "Epoch 290/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5408 - acc: 0.7617 - val_loss: 0.5006 - val_acc: 0.7979\n",
      "Epoch 291/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5400 - acc: 0.7691 - val_loss: 0.4980 - val_acc: 0.7896\n",
      "Epoch 292/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5377 - acc: 0.7684 - val_loss: 0.4991 - val_acc: 0.7931\n",
      "Epoch 293/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5340 - acc: 0.7668 - val_loss: 0.4973 - val_acc: 0.7952\n",
      "Epoch 294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5377 - acc: 0.7587 - val_loss: 0.4983 - val_acc: 0.7938\n",
      "Epoch 295/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5360 - acc: 0.7652 - val_loss: 0.4998 - val_acc: 0.7875\n",
      "Epoch 296/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5370 - acc: 0.7557 - val_loss: 0.4992 - val_acc: 0.7924\n",
      "Epoch 297/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5379 - acc: 0.7601 - val_loss: 0.4983 - val_acc: 0.7958\n",
      "Epoch 298/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5290 - acc: 0.7640 - val_loss: 0.5001 - val_acc: 0.7931\n",
      "Epoch 299/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.5344 - acc: 0.7606 - val_loss: 0.5007 - val_acc: 0.7875\n",
      "Epoch 300/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5396 - acc: 0.7659 - val_loss: 0.5015 - val_acc: 0.7882\n",
      "Epoch 301/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5377 - acc: 0.7656 - val_loss: 0.5010 - val_acc: 0.7910\n",
      "Epoch 302/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5333 - acc: 0.7585 - val_loss: 0.4998 - val_acc: 0.7972\n",
      "Epoch 303/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5370 - acc: 0.7640 - val_loss: 0.4996 - val_acc: 0.7993\n",
      "Epoch 304/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5427 - acc: 0.7654 - val_loss: 0.5077 - val_acc: 0.7785\n",
      "Epoch 305/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5360 - acc: 0.7606 - val_loss: 0.4983 - val_acc: 0.7938\n",
      "Epoch 306/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5346 - acc: 0.7670 - val_loss: 0.5004 - val_acc: 0.7875\n",
      "Epoch 307/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.5304 - acc: 0.7698 - val_loss: 0.4958 - val_acc: 0.7952\n",
      "Epoch 308/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5407 - acc: 0.7587 - val_loss: 0.4976 - val_acc: 0.7917\n",
      "Epoch 309/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5389 - acc: 0.7562 - val_loss: 0.4993 - val_acc: 0.7917\n",
      "Epoch 310/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5390 - acc: 0.7592 - val_loss: 0.4992 - val_acc: 0.7889\n",
      "Epoch 311/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5315 - acc: 0.7656 - val_loss: 0.4965 - val_acc: 0.7924\n",
      "Epoch 312/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5330 - acc: 0.7656 - val_loss: 0.4988 - val_acc: 0.7896\n",
      "Epoch 313/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5347 - acc: 0.7633 - val_loss: 0.4970 - val_acc: 0.7903\n",
      "Epoch 314/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5338 - acc: 0.7721 - val_loss: 0.5016 - val_acc: 0.7848\n",
      "Epoch 315/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5329 - acc: 0.7585 - val_loss: 0.4964 - val_acc: 0.7903\n",
      "Epoch 316/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5320 - acc: 0.7654 - val_loss: 0.4981 - val_acc: 0.7896\n",
      "Epoch 317/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5319 - acc: 0.7645 - val_loss: 0.4972 - val_acc: 0.7910\n",
      "Epoch 318/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5307 - acc: 0.7721 - val_loss: 0.4964 - val_acc: 0.7875\n",
      "Epoch 319/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.5243 - acc: 0.7661 - val_loss: 0.4980 - val_acc: 0.7882\n",
      "Epoch 320/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5321 - acc: 0.7696 - val_loss: 0.5001 - val_acc: 0.7924\n",
      "Epoch 321/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5289 - acc: 0.7675 - val_loss: 0.4992 - val_acc: 0.7931\n",
      "Epoch 322/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5297 - acc: 0.7725 - val_loss: 0.5014 - val_acc: 0.7882\n",
      "Epoch 323/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5320 - acc: 0.7624 - val_loss: 0.5045 - val_acc: 0.7827\n",
      "Epoch 324/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5293 - acc: 0.7700 - val_loss: 0.5085 - val_acc: 0.7834\n",
      "Epoch 325/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5258 - acc: 0.7626 - val_loss: 0.4967 - val_acc: 0.7958\n",
      "Epoch 326/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5262 - acc: 0.7670 - val_loss: 0.4961 - val_acc: 0.7903\n",
      "Epoch 327/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5206 - acc: 0.7682 - val_loss: 0.4959 - val_acc: 0.7952\n",
      "Epoch 328/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5259 - acc: 0.7640 - val_loss: 0.4948 - val_acc: 0.7917\n",
      "Epoch 329/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5307 - acc: 0.7622 - val_loss: 0.4964 - val_acc: 0.7896\n",
      "Epoch 330/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.5290 - acc: 0.7582 - val_loss: 0.4983 - val_acc: 0.7855\n",
      "Epoch 331/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5325 - acc: 0.7633 - val_loss: 0.4962 - val_acc: 0.7931\n",
      "Epoch 332/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5211 - acc: 0.7672 - val_loss: 0.4961 - val_acc: 0.7986\n",
      "Epoch 333/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5376 - acc: 0.7636 - val_loss: 0.4954 - val_acc: 0.7938\n",
      "Epoch 334/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5242 - acc: 0.7691 - val_loss: 0.4955 - val_acc: 0.7903\n",
      "Epoch 335/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5392 - acc: 0.7582 - val_loss: 0.4974 - val_acc: 0.7931\n",
      "Epoch 336/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5330 - acc: 0.7652 - val_loss: 0.4964 - val_acc: 0.7917\n",
      "Epoch 337/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5177 - acc: 0.7712 - val_loss: 0.4949 - val_acc: 0.7924\n",
      "Epoch 338/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5258 - acc: 0.7679 - val_loss: 0.4958 - val_acc: 0.7958\n",
      "Epoch 339/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5310 - acc: 0.7670 - val_loss: 0.5011 - val_acc: 0.7882\n",
      "Epoch 340/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5269 - acc: 0.7659 - val_loss: 0.4973 - val_acc: 0.7889\n",
      "Epoch 341/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5222 - acc: 0.7631 - val_loss: 0.4970 - val_acc: 0.7938\n",
      "Epoch 342/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5207 - acc: 0.7668 - val_loss: 0.4977 - val_acc: 0.7903\n",
      "Epoch 343/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5299 - acc: 0.7677 - val_loss: 0.5049 - val_acc: 0.7875\n",
      "Epoch 344/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5172 - acc: 0.7672 - val_loss: 0.5000 - val_acc: 0.7882\n",
      "Epoch 345/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5316 - acc: 0.7684 - val_loss: 0.4991 - val_acc: 0.7965\n",
      "Epoch 346/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5300 - acc: 0.7668 - val_loss: 0.4977 - val_acc: 0.7952\n",
      "Epoch 347/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5183 - acc: 0.7700 - val_loss: 0.4959 - val_acc: 0.7924\n",
      "Epoch 348/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5171 - acc: 0.7742 - val_loss: 0.4946 - val_acc: 0.7910\n",
      "Epoch 349/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5302 - acc: 0.7649 - val_loss: 0.4958 - val_acc: 0.7910\n",
      "Epoch 350/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5261 - acc: 0.7640 - val_loss: 0.4947 - val_acc: 0.7972\n",
      "Epoch 351/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5331 - acc: 0.7686 - val_loss: 0.4976 - val_acc: 0.7945\n",
      "Epoch 352/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5269 - acc: 0.7672 - val_loss: 0.4967 - val_acc: 0.7965\n",
      "Epoch 353/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5336 - acc: 0.7573 - val_loss: 0.4958 - val_acc: 0.7958\n",
      "Epoch 354/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5255 - acc: 0.7626 - val_loss: 0.4949 - val_acc: 0.7889\n",
      "Epoch 355/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5290 - acc: 0.7677 - val_loss: 0.4964 - val_acc: 0.7903\n",
      "Epoch 356/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5257 - acc: 0.7633 - val_loss: 0.5071 - val_acc: 0.7827\n",
      "Epoch 357/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5198 - acc: 0.7633 - val_loss: 0.4949 - val_acc: 0.7910\n",
      "Epoch 358/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5255 - acc: 0.7642 - val_loss: 0.4944 - val_acc: 0.7924\n",
      "Epoch 359/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5317 - acc: 0.7626 - val_loss: 0.5001 - val_acc: 0.7875\n",
      "Epoch 360/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5305 - acc: 0.7663 - val_loss: 0.4962 - val_acc: 0.7945\n",
      "Epoch 361/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5127 - acc: 0.7698 - val_loss: 0.4964 - val_acc: 0.7903\n",
      "Epoch 362/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5213 - acc: 0.7707 - val_loss: 0.4956 - val_acc: 0.7882\n",
      "Epoch 363/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5165 - acc: 0.7742 - val_loss: 0.4952 - val_acc: 0.7896\n",
      "Epoch 364/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5277 - acc: 0.7698 - val_loss: 0.4957 - val_acc: 0.7965\n",
      "Epoch 365/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5208 - acc: 0.7709 - val_loss: 0.4969 - val_acc: 0.7903\n",
      "Epoch 366/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5195 - acc: 0.7691 - val_loss: 0.4946 - val_acc: 0.7882\n",
      "Epoch 367/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5231 - acc: 0.7682 - val_loss: 0.4940 - val_acc: 0.7882\n",
      "Epoch 368/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5195 - acc: 0.7693 - val_loss: 0.4945 - val_acc: 0.7938\n",
      "Epoch 369/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5232 - acc: 0.7728 - val_loss: 0.4977 - val_acc: 0.7903\n",
      "Epoch 370/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5229 - acc: 0.7691 - val_loss: 0.4941 - val_acc: 0.7869\n",
      "Epoch 371/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5250 - acc: 0.7709 - val_loss: 0.4950 - val_acc: 0.7896\n",
      "Epoch 372/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5176 - acc: 0.7700 - val_loss: 0.4934 - val_acc: 0.7903\n",
      "Epoch 373/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5189 - acc: 0.7666 - val_loss: 0.4942 - val_acc: 0.7869\n",
      "Epoch 374/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5315 - acc: 0.7642 - val_loss: 0.4975 - val_acc: 0.7889\n",
      "Epoch 375/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5148 - acc: 0.7723 - val_loss: 0.4935 - val_acc: 0.7910\n",
      "Epoch 376/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5271 - acc: 0.7714 - val_loss: 0.4950 - val_acc: 0.7945\n",
      "Epoch 377/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5324 - acc: 0.7716 - val_loss: 0.4961 - val_acc: 0.7945\n",
      "Epoch 378/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5184 - acc: 0.7642 - val_loss: 0.4943 - val_acc: 0.7903\n",
      "Epoch 379/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5222 - acc: 0.7707 - val_loss: 0.4964 - val_acc: 0.7896\n",
      "Epoch 380/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5232 - acc: 0.7642 - val_loss: 0.4939 - val_acc: 0.7931\n",
      "Epoch 381/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5120 - acc: 0.7781 - val_loss: 0.4948 - val_acc: 0.7903\n",
      "Epoch 382/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5173 - acc: 0.7725 - val_loss: 0.4935 - val_acc: 0.7896\n",
      "Epoch 383/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5354 - acc: 0.7668 - val_loss: 0.4951 - val_acc: 0.7910\n",
      "Epoch 384/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5191 - acc: 0.7719 - val_loss: 0.4940 - val_acc: 0.7938\n",
      "Epoch 385/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5144 - acc: 0.7668 - val_loss: 0.4944 - val_acc: 0.7869\n",
      "Epoch 386/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5210 - acc: 0.7693 - val_loss: 0.4946 - val_acc: 0.7882\n",
      "Epoch 387/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5176 - acc: 0.7749 - val_loss: 0.4945 - val_acc: 0.7889\n",
      "Epoch 388/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5166 - acc: 0.7693 - val_loss: 0.4981 - val_acc: 0.7882\n",
      "Epoch 389/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5266 - acc: 0.7672 - val_loss: 0.4948 - val_acc: 0.7958\n",
      "Epoch 390/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5211 - acc: 0.7677 - val_loss: 0.4930 - val_acc: 0.7917\n",
      "Epoch 391/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5185 - acc: 0.7716 - val_loss: 0.4972 - val_acc: 0.7910\n",
      "Epoch 392/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5135 - acc: 0.7700 - val_loss: 0.4942 - val_acc: 0.7958\n",
      "Epoch 393/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5220 - acc: 0.7642 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 394/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5263 - acc: 0.7622 - val_loss: 0.4944 - val_acc: 0.7924\n",
      "Epoch 395/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5132 - acc: 0.7659 - val_loss: 0.4960 - val_acc: 0.7903\n",
      "Epoch 396/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5186 - acc: 0.7682 - val_loss: 0.4953 - val_acc: 0.7910\n",
      "Epoch 397/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5187 - acc: 0.7698 - val_loss: 0.4965 - val_acc: 0.7889\n",
      "Epoch 398/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5121 - acc: 0.7712 - val_loss: 0.4987 - val_acc: 0.7917\n",
      "Epoch 399/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5216 - acc: 0.7684 - val_loss: 0.4938 - val_acc: 0.7889\n",
      "Epoch 400/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5166 - acc: 0.7693 - val_loss: 0.4966 - val_acc: 0.7910\n",
      "Epoch 401/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5181 - acc: 0.7684 - val_loss: 0.4933 - val_acc: 0.7869\n",
      "Epoch 402/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5120 - acc: 0.7744 - val_loss: 0.4955 - val_acc: 0.7924\n",
      "Epoch 403/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5207 - acc: 0.7691 - val_loss: 0.4932 - val_acc: 0.7889\n",
      "Epoch 404/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5085 - acc: 0.7779 - val_loss: 0.4941 - val_acc: 0.7896\n",
      "Epoch 405/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5299 - acc: 0.7638 - val_loss: 0.4942 - val_acc: 0.7882\n",
      "Epoch 406/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5154 - acc: 0.7691 - val_loss: 0.4940 - val_acc: 0.7938\n",
      "Epoch 407/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5047 - acc: 0.7679 - val_loss: 0.4985 - val_acc: 0.7903\n",
      "Epoch 408/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5167 - acc: 0.7636 - val_loss: 0.4939 - val_acc: 0.7896\n",
      "Epoch 409/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5193 - acc: 0.7728 - val_loss: 0.4934 - val_acc: 0.7931\n",
      "Epoch 410/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5125 - acc: 0.7758 - val_loss: 0.4930 - val_acc: 0.7958\n",
      "Epoch 411/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5179 - acc: 0.7749 - val_loss: 0.4936 - val_acc: 0.7965\n",
      "Epoch 412/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5198 - acc: 0.7728 - val_loss: 0.4949 - val_acc: 0.7924\n",
      "Epoch 413/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5083 - acc: 0.7719 - val_loss: 0.4934 - val_acc: 0.7924\n",
      "Epoch 414/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5129 - acc: 0.7735 - val_loss: 0.4940 - val_acc: 0.7889\n",
      "Epoch 415/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5089 - acc: 0.7779 - val_loss: 0.4937 - val_acc: 0.7875\n",
      "Epoch 416/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5110 - acc: 0.7719 - val_loss: 0.4972 - val_acc: 0.7875\n",
      "Epoch 417/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5178 - acc: 0.7714 - val_loss: 0.4930 - val_acc: 0.7903\n",
      "Epoch 418/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5273 - acc: 0.7659 - val_loss: 0.4940 - val_acc: 0.7979\n",
      "Epoch 419/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5192 - acc: 0.7675 - val_loss: 0.4935 - val_acc: 0.7938\n",
      "Epoch 420/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5151 - acc: 0.7762 - val_loss: 0.4957 - val_acc: 0.7903\n",
      "Epoch 421/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5150 - acc: 0.7735 - val_loss: 0.5009 - val_acc: 0.7889\n",
      "Epoch 422/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5110 - acc: 0.7719 - val_loss: 0.4945 - val_acc: 0.7889\n",
      "Epoch 423/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5142 - acc: 0.7700 - val_loss: 0.4937 - val_acc: 0.7903\n",
      "Epoch 424/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5171 - acc: 0.7760 - val_loss: 0.4937 - val_acc: 0.7882\n",
      "Epoch 425/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5233 - acc: 0.7672 - val_loss: 0.4938 - val_acc: 0.7882\n",
      "Epoch 426/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5200 - acc: 0.7698 - val_loss: 0.4930 - val_acc: 0.7917\n",
      "Epoch 427/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5127 - acc: 0.7746 - val_loss: 0.4926 - val_acc: 0.7889\n",
      "Epoch 428/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5140 - acc: 0.7795 - val_loss: 0.4946 - val_acc: 0.7903\n",
      "Epoch 429/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5123 - acc: 0.7610 - val_loss: 0.4989 - val_acc: 0.7903\n",
      "Epoch 430/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5062 - acc: 0.7730 - val_loss: 0.4997 - val_acc: 0.7848\n",
      "Epoch 431/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5119 - acc: 0.7698 - val_loss: 0.4933 - val_acc: 0.7889\n",
      "Epoch 432/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5117 - acc: 0.7799 - val_loss: 0.4932 - val_acc: 0.7924\n",
      "Epoch 433/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5179 - acc: 0.7732 - val_loss: 0.4950 - val_acc: 0.7903\n",
      "Epoch 434/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5048 - acc: 0.7725 - val_loss: 0.4932 - val_acc: 0.7924\n",
      "Epoch 435/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5065 - acc: 0.7716 - val_loss: 0.4928 - val_acc: 0.7910\n",
      "Epoch 436/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5035 - acc: 0.7785 - val_loss: 0.4931 - val_acc: 0.7889\n",
      "Epoch 437/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5078 - acc: 0.7751 - val_loss: 0.4972 - val_acc: 0.7903\n",
      "Epoch 438/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5061 - acc: 0.7755 - val_loss: 0.4911 - val_acc: 0.7882\n",
      "Epoch 439/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5134 - acc: 0.7730 - val_loss: 0.4934 - val_acc: 0.7938\n",
      "Epoch 440/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5034 - acc: 0.7765 - val_loss: 0.4938 - val_acc: 0.7896\n",
      "Epoch 441/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5046 - acc: 0.7762 - val_loss: 0.4919 - val_acc: 0.7903\n",
      "Epoch 442/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5195 - acc: 0.7702 - val_loss: 0.4928 - val_acc: 0.7910\n",
      "Epoch 443/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5129 - acc: 0.7612 - val_loss: 0.4932 - val_acc: 0.7910\n",
      "Epoch 444/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5169 - acc: 0.7686 - val_loss: 0.4935 - val_acc: 0.7875\n",
      "Epoch 445/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5056 - acc: 0.7797 - val_loss: 0.4939 - val_acc: 0.7924\n",
      "Epoch 446/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5119 - acc: 0.7769 - val_loss: 0.4925 - val_acc: 0.7945\n",
      "Epoch 447/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.5016 - acc: 0.7822 - val_loss: 0.4974 - val_acc: 0.7896\n",
      "Epoch 448/2000\n",
      "4335/4335 [==============================] - 0s 31us/step - loss: 0.5097 - acc: 0.7728 - val_loss: 0.4918 - val_acc: 0.7945\n",
      "Epoch 449/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.5154 - acc: 0.7661 - val_loss: 0.4937 - val_acc: 0.7875\n",
      "Epoch 450/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.5075 - acc: 0.7767 - val_loss: 0.4939 - val_acc: 0.7889\n",
      "Epoch 451/2000\n",
      "4335/4335 [==============================] - 0s 28us/step - loss: 0.5157 - acc: 0.7751 - val_loss: 0.4954 - val_acc: 0.7917\n",
      "Epoch 452/2000\n",
      "4335/4335 [==============================] - 0s 28us/step - loss: 0.5066 - acc: 0.7702 - val_loss: 0.4956 - val_acc: 0.7869\n",
      "Epoch 453/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.5077 - acc: 0.7758 - val_loss: 0.4968 - val_acc: 0.7931\n",
      "Epoch 454/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5131 - acc: 0.7709 - val_loss: 0.4924 - val_acc: 0.7889\n",
      "Epoch 455/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5164 - acc: 0.7772 - val_loss: 0.4958 - val_acc: 0.7896\n",
      "Epoch 456/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5130 - acc: 0.7698 - val_loss: 0.4953 - val_acc: 0.7889\n",
      "Epoch 457/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5164 - acc: 0.7716 - val_loss: 0.4957 - val_acc: 0.7889\n",
      "Epoch 458/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5070 - acc: 0.7753 - val_loss: 0.4936 - val_acc: 0.7910\n",
      "Epoch 459/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5035 - acc: 0.7767 - val_loss: 0.4936 - val_acc: 0.7917\n",
      "Epoch 460/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5093 - acc: 0.7705 - val_loss: 0.4955 - val_acc: 0.7889\n",
      "Epoch 461/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5110 - acc: 0.7723 - val_loss: 0.4934 - val_acc: 0.7875\n",
      "Epoch 462/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5067 - acc: 0.7730 - val_loss: 0.4943 - val_acc: 0.7889\n",
      "Epoch 463/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5057 - acc: 0.7719 - val_loss: 0.4921 - val_acc: 0.7910\n",
      "Epoch 464/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5011 - acc: 0.7827 - val_loss: 0.4924 - val_acc: 0.7924\n",
      "Epoch 465/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5136 - acc: 0.7691 - val_loss: 0.4930 - val_acc: 0.7862\n",
      "Epoch 466/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5115 - acc: 0.7709 - val_loss: 0.4919 - val_acc: 0.7882\n",
      "Epoch 467/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5038 - acc: 0.7797 - val_loss: 0.4965 - val_acc: 0.7903\n",
      "Epoch 468/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5051 - acc: 0.7809 - val_loss: 0.4930 - val_acc: 0.7882\n",
      "Epoch 469/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4994 - acc: 0.7728 - val_loss: 0.4920 - val_acc: 0.7903\n",
      "Epoch 470/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5035 - acc: 0.7714 - val_loss: 0.4944 - val_acc: 0.7869\n",
      "Epoch 471/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5175 - acc: 0.7649 - val_loss: 0.4926 - val_acc: 0.7882\n",
      "Epoch 472/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5092 - acc: 0.7749 - val_loss: 0.4951 - val_acc: 0.7875\n",
      "Epoch 473/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5112 - acc: 0.7749 - val_loss: 0.4938 - val_acc: 0.7931\n",
      "Epoch 474/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5080 - acc: 0.7769 - val_loss: 0.4916 - val_acc: 0.7945\n",
      "Epoch 475/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5109 - acc: 0.7767 - val_loss: 0.4941 - val_acc: 0.7875\n",
      "Epoch 476/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5127 - acc: 0.7693 - val_loss: 0.4940 - val_acc: 0.7889\n",
      "Epoch 477/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5023 - acc: 0.7762 - val_loss: 0.4935 - val_acc: 0.7855\n",
      "Epoch 478/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4987 - acc: 0.7774 - val_loss: 0.4935 - val_acc: 0.7882\n",
      "Epoch 479/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5143 - acc: 0.7716 - val_loss: 0.4915 - val_acc: 0.7875\n",
      "Epoch 480/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4984 - acc: 0.7790 - val_loss: 0.4924 - val_acc: 0.7862\n",
      "Epoch 481/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5153 - acc: 0.7755 - val_loss: 0.4909 - val_acc: 0.7917\n",
      "Epoch 482/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5035 - acc: 0.7820 - val_loss: 0.4936 - val_acc: 0.7896\n",
      "Epoch 483/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5087 - acc: 0.7728 - val_loss: 0.4940 - val_acc: 0.7896\n",
      "Epoch 484/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5049 - acc: 0.7742 - val_loss: 0.4934 - val_acc: 0.7869\n",
      "Epoch 485/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5040 - acc: 0.7767 - val_loss: 0.4925 - val_acc: 0.7882\n",
      "Epoch 486/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5137 - acc: 0.7744 - val_loss: 0.4951 - val_acc: 0.7882\n",
      "Epoch 487/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5128 - acc: 0.7684 - val_loss: 0.4926 - val_acc: 0.7931\n",
      "Epoch 488/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5021 - acc: 0.7825 - val_loss: 0.4936 - val_acc: 0.7875\n",
      "Epoch 489/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5200 - acc: 0.7661 - val_loss: 0.4928 - val_acc: 0.7924\n",
      "Epoch 490/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4968 - acc: 0.7813 - val_loss: 0.4926 - val_acc: 0.7896\n",
      "Epoch 491/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5065 - acc: 0.7790 - val_loss: 0.4935 - val_acc: 0.7889\n",
      "Epoch 492/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5036 - acc: 0.7767 - val_loss: 0.4928 - val_acc: 0.7889\n",
      "Epoch 493/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5125 - acc: 0.7702 - val_loss: 0.4919 - val_acc: 0.7875\n",
      "Epoch 494/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5033 - acc: 0.7804 - val_loss: 0.4932 - val_acc: 0.7938\n",
      "Epoch 495/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5116 - acc: 0.7656 - val_loss: 0.4940 - val_acc: 0.7869\n",
      "Epoch 496/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5128 - acc: 0.7700 - val_loss: 0.4939 - val_acc: 0.7917\n",
      "Epoch 497/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5020 - acc: 0.7802 - val_loss: 0.4953 - val_acc: 0.7896\n",
      "Epoch 498/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5065 - acc: 0.7758 - val_loss: 0.4940 - val_acc: 0.7931\n",
      "Epoch 499/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5084 - acc: 0.7730 - val_loss: 0.4949 - val_acc: 0.7869\n",
      "Epoch 500/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5068 - acc: 0.7742 - val_loss: 0.4971 - val_acc: 0.7917\n",
      "Epoch 501/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5071 - acc: 0.7735 - val_loss: 0.4937 - val_acc: 0.7862\n",
      "Epoch 502/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5064 - acc: 0.7804 - val_loss: 0.4935 - val_acc: 0.7882\n",
      "Epoch 503/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5068 - acc: 0.7707 - val_loss: 0.4928 - val_acc: 0.7938\n",
      "Epoch 504/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4960 - acc: 0.7781 - val_loss: 0.4923 - val_acc: 0.7896\n",
      "Epoch 505/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5082 - acc: 0.7767 - val_loss: 0.4937 - val_acc: 0.7889\n",
      "Epoch 506/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4953 - acc: 0.7822 - val_loss: 0.4933 - val_acc: 0.7917\n",
      "Epoch 507/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5030 - acc: 0.7758 - val_loss: 0.4968 - val_acc: 0.7889\n",
      "Epoch 508/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4979 - acc: 0.7769 - val_loss: 0.4996 - val_acc: 0.7896\n",
      "Epoch 509/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5054 - acc: 0.7707 - val_loss: 0.4913 - val_acc: 0.7889\n",
      "Epoch 510/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5099 - acc: 0.7725 - val_loss: 0.4933 - val_acc: 0.7848\n",
      "Epoch 511/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4985 - acc: 0.7709 - val_loss: 0.4958 - val_acc: 0.7841\n",
      "Epoch 512/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5024 - acc: 0.7832 - val_loss: 0.4913 - val_acc: 0.7855\n",
      "Epoch 513/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5052 - acc: 0.7709 - val_loss: 0.4913 - val_acc: 0.7882\n",
      "Epoch 514/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5061 - acc: 0.7725 - val_loss: 0.4918 - val_acc: 0.7910\n",
      "Epoch 515/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4988 - acc: 0.7755 - val_loss: 0.4940 - val_acc: 0.7945\n",
      "Epoch 516/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5057 - acc: 0.7822 - val_loss: 0.4942 - val_acc: 0.7882\n",
      "Epoch 517/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5047 - acc: 0.7799 - val_loss: 0.4930 - val_acc: 0.7855\n",
      "Epoch 518/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5056 - acc: 0.7746 - val_loss: 0.4990 - val_acc: 0.7910\n",
      "Epoch 519/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5036 - acc: 0.7776 - val_loss: 0.4924 - val_acc: 0.7945\n",
      "Epoch 520/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5024 - acc: 0.7767 - val_loss: 0.4948 - val_acc: 0.7875\n",
      "Epoch 521/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4973 - acc: 0.7755 - val_loss: 0.4951 - val_acc: 0.7910\n",
      "Epoch 522/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4979 - acc: 0.7797 - val_loss: 0.4950 - val_acc: 0.7924\n",
      "Epoch 523/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5033 - acc: 0.7723 - val_loss: 0.4987 - val_acc: 0.7917\n",
      "Epoch 524/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5055 - acc: 0.7829 - val_loss: 0.4943 - val_acc: 0.7896\n",
      "Epoch 525/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5036 - acc: 0.7797 - val_loss: 0.4947 - val_acc: 0.7875\n",
      "Epoch 526/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5074 - acc: 0.7758 - val_loss: 0.4906 - val_acc: 0.7917\n",
      "Epoch 527/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5059 - acc: 0.7774 - val_loss: 0.4935 - val_acc: 0.7896\n",
      "Epoch 528/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5009 - acc: 0.7762 - val_loss: 0.4920 - val_acc: 0.7903\n",
      "Epoch 529/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4995 - acc: 0.7732 - val_loss: 0.4932 - val_acc: 0.7917\n",
      "Epoch 530/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5062 - acc: 0.7804 - val_loss: 0.4977 - val_acc: 0.7910\n",
      "Epoch 531/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4977 - acc: 0.7779 - val_loss: 0.4957 - val_acc: 0.7910\n",
      "Epoch 532/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5019 - acc: 0.7760 - val_loss: 0.4948 - val_acc: 0.7903\n",
      "Epoch 533/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5014 - acc: 0.7815 - val_loss: 0.4908 - val_acc: 0.7910\n",
      "Epoch 534/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5090 - acc: 0.7714 - val_loss: 0.4923 - val_acc: 0.7896\n",
      "Epoch 535/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4985 - acc: 0.7866 - val_loss: 0.4921 - val_acc: 0.7903\n",
      "Epoch 536/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4943 - acc: 0.7779 - val_loss: 0.4921 - val_acc: 0.7917\n",
      "Epoch 537/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4972 - acc: 0.7776 - val_loss: 0.4934 - val_acc: 0.7910\n",
      "Epoch 538/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5009 - acc: 0.7772 - val_loss: 0.4929 - val_acc: 0.7917\n",
      "Epoch 539/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4937 - acc: 0.7822 - val_loss: 0.4916 - val_acc: 0.7903\n",
      "Epoch 540/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5025 - acc: 0.7802 - val_loss: 0.4926 - val_acc: 0.7889\n",
      "Epoch 541/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4989 - acc: 0.7781 - val_loss: 0.4953 - val_acc: 0.7896\n",
      "Epoch 542/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5043 - acc: 0.7772 - val_loss: 0.4915 - val_acc: 0.7931\n",
      "Epoch 543/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4952 - acc: 0.7790 - val_loss: 0.4925 - val_acc: 0.7903\n",
      "Epoch 544/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4992 - acc: 0.7804 - val_loss: 0.4911 - val_acc: 0.7882\n",
      "Epoch 545/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5067 - acc: 0.7714 - val_loss: 0.4924 - val_acc: 0.7862\n",
      "Epoch 546/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4952 - acc: 0.7841 - val_loss: 0.4940 - val_acc: 0.7875\n",
      "Epoch 547/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5022 - acc: 0.7799 - val_loss: 0.4921 - val_acc: 0.7862\n",
      "Epoch 548/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4943 - acc: 0.7827 - val_loss: 0.4907 - val_acc: 0.7889\n",
      "Epoch 549/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5001 - acc: 0.7827 - val_loss: 0.4914 - val_acc: 0.7889\n",
      "Epoch 550/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4990 - acc: 0.7813 - val_loss: 0.4942 - val_acc: 0.7869\n",
      "Epoch 551/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4920 - acc: 0.7894 - val_loss: 0.4907 - val_acc: 0.7972\n",
      "Epoch 552/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4979 - acc: 0.7848 - val_loss: 0.4926 - val_acc: 0.7875\n",
      "Epoch 553/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5035 - acc: 0.7809 - val_loss: 0.4921 - val_acc: 0.7855\n",
      "Epoch 554/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.5011 - acc: 0.7804 - val_loss: 0.4919 - val_acc: 0.7882\n",
      "Epoch 555/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4980 - acc: 0.7783 - val_loss: 0.4905 - val_acc: 0.7882\n",
      "Epoch 556/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4992 - acc: 0.7767 - val_loss: 0.4951 - val_acc: 0.7889\n",
      "Epoch 557/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4987 - acc: 0.7682 - val_loss: 0.4923 - val_acc: 0.7889\n",
      "Epoch 558/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5032 - acc: 0.7755 - val_loss: 0.4909 - val_acc: 0.7924\n",
      "Epoch 559/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5028 - acc: 0.7744 - val_loss: 0.4929 - val_acc: 0.7896\n",
      "Epoch 560/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4960 - acc: 0.7836 - val_loss: 0.4909 - val_acc: 0.7869\n",
      "Epoch 561/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5073 - acc: 0.7659 - val_loss: 0.4924 - val_acc: 0.7903\n",
      "Epoch 562/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4925 - acc: 0.7852 - val_loss: 0.4917 - val_acc: 0.7896\n",
      "Epoch 563/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.5038 - acc: 0.7783 - val_loss: 0.4971 - val_acc: 0.7869\n",
      "Epoch 564/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5022 - acc: 0.7815 - val_loss: 0.4912 - val_acc: 0.7869\n",
      "Epoch 565/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4931 - acc: 0.7785 - val_loss: 0.4929 - val_acc: 0.7862\n",
      "Epoch 566/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5023 - acc: 0.7751 - val_loss: 0.4942 - val_acc: 0.7882\n",
      "Epoch 567/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5014 - acc: 0.7739 - val_loss: 0.4928 - val_acc: 0.7917\n",
      "Epoch 568/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4964 - acc: 0.7781 - val_loss: 0.4962 - val_acc: 0.7869\n",
      "Epoch 569/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4956 - acc: 0.7767 - val_loss: 0.4927 - val_acc: 0.7917\n",
      "Epoch 570/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4928 - acc: 0.7827 - val_loss: 0.4921 - val_acc: 0.7931\n",
      "Epoch 571/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4977 - acc: 0.7769 - val_loss: 0.4926 - val_acc: 0.7875\n",
      "Epoch 572/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5040 - acc: 0.7834 - val_loss: 0.4923 - val_acc: 0.7855\n",
      "Epoch 573/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4976 - acc: 0.7762 - val_loss: 0.4927 - val_acc: 0.7903\n",
      "Epoch 574/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4959 - acc: 0.7809 - val_loss: 0.4977 - val_acc: 0.7903\n",
      "Epoch 575/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5025 - acc: 0.7792 - val_loss: 0.4943 - val_acc: 0.7896\n",
      "Epoch 576/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4892 - acc: 0.7878 - val_loss: 0.4923 - val_acc: 0.7938\n",
      "Epoch 577/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4950 - acc: 0.7836 - val_loss: 0.4949 - val_acc: 0.7931\n",
      "Epoch 578/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4952 - acc: 0.7785 - val_loss: 0.4929 - val_acc: 0.7896\n",
      "Epoch 579/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5023 - acc: 0.7730 - val_loss: 0.4942 - val_acc: 0.7917\n",
      "Epoch 580/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4945 - acc: 0.7785 - val_loss: 0.4981 - val_acc: 0.7903\n",
      "Epoch 581/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5061 - acc: 0.7742 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 582/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5010 - acc: 0.7760 - val_loss: 0.4925 - val_acc: 0.7903\n",
      "Epoch 583/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4916 - acc: 0.7751 - val_loss: 0.4936 - val_acc: 0.7869\n",
      "Epoch 584/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4963 - acc: 0.7804 - val_loss: 0.4963 - val_acc: 0.7882\n",
      "Epoch 585/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4974 - acc: 0.7809 - val_loss: 0.4961 - val_acc: 0.7931\n",
      "Epoch 586/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.4986 - acc: 0.7753 - val_loss: 0.4952 - val_acc: 0.7855\n",
      "Epoch 587/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4909 - acc: 0.7799 - val_loss: 0.4953 - val_acc: 0.7869\n",
      "Epoch 588/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4963 - acc: 0.7783 - val_loss: 0.4934 - val_acc: 0.7910\n",
      "Epoch 589/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4964 - acc: 0.7809 - val_loss: 0.4948 - val_acc: 0.7889\n",
      "Epoch 590/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4977 - acc: 0.7859 - val_loss: 0.4950 - val_acc: 0.7910\n",
      "Epoch 591/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4962 - acc: 0.7781 - val_loss: 0.4932 - val_acc: 0.7855\n",
      "Epoch 592/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4950 - acc: 0.7804 - val_loss: 0.4955 - val_acc: 0.7910\n",
      "Epoch 593/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5017 - acc: 0.7772 - val_loss: 0.4939 - val_acc: 0.7931\n",
      "Epoch 594/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4967 - acc: 0.7795 - val_loss: 0.4956 - val_acc: 0.7931\n",
      "Epoch 595/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4945 - acc: 0.7781 - val_loss: 0.4924 - val_acc: 0.7882\n",
      "Epoch 596/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4969 - acc: 0.7809 - val_loss: 0.4929 - val_acc: 0.7945\n",
      "Epoch 597/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4973 - acc: 0.7845 - val_loss: 0.4947 - val_acc: 0.7889\n",
      "Epoch 598/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4911 - acc: 0.7822 - val_loss: 0.4931 - val_acc: 0.7882\n",
      "Epoch 599/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4958 - acc: 0.7829 - val_loss: 0.4924 - val_acc: 0.7841\n",
      "Epoch 600/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4906 - acc: 0.7811 - val_loss: 0.4955 - val_acc: 0.7875\n",
      "Epoch 601/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4966 - acc: 0.7755 - val_loss: 0.4924 - val_acc: 0.7903\n",
      "Epoch 602/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4992 - acc: 0.7802 - val_loss: 0.4961 - val_acc: 0.7869\n",
      "Epoch 603/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4986 - acc: 0.7753 - val_loss: 0.4933 - val_acc: 0.7924\n",
      "Epoch 604/2000\n",
      "4335/4335 [==============================] - 0s 22us/step - loss: 0.4947 - acc: 0.7815 - val_loss: 0.4939 - val_acc: 0.7903\n",
      "Epoch 605/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4948 - acc: 0.7841 - val_loss: 0.4949 - val_acc: 0.7931\n",
      "Epoch 606/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5031 - acc: 0.7758 - val_loss: 0.4920 - val_acc: 0.7917\n",
      "Epoch 607/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4903 - acc: 0.7834 - val_loss: 0.4947 - val_acc: 0.7903\n",
      "Epoch 608/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4970 - acc: 0.7827 - val_loss: 0.5004 - val_acc: 0.7841\n",
      "Epoch 609/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4960 - acc: 0.7818 - val_loss: 0.4926 - val_acc: 0.7875\n",
      "Epoch 610/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4916 - acc: 0.7892 - val_loss: 0.4912 - val_acc: 0.7882\n",
      "Epoch 611/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4933 - acc: 0.7781 - val_loss: 0.4928 - val_acc: 0.7889\n",
      "Epoch 612/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4949 - acc: 0.7758 - val_loss: 0.4977 - val_acc: 0.7869\n",
      "Epoch 613/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4946 - acc: 0.7841 - val_loss: 0.4912 - val_acc: 0.7896\n",
      "Epoch 614/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4958 - acc: 0.7839 - val_loss: 0.4923 - val_acc: 0.7910\n",
      "Epoch 615/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4900 - acc: 0.7809 - val_loss: 0.4925 - val_acc: 0.7924\n",
      "Epoch 616/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4922 - acc: 0.7822 - val_loss: 0.4924 - val_acc: 0.7869\n",
      "Epoch 617/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4916 - acc: 0.7776 - val_loss: 0.4941 - val_acc: 0.7862\n",
      "Epoch 618/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4993 - acc: 0.7755 - val_loss: 0.4991 - val_acc: 0.7910\n",
      "Epoch 619/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4981 - acc: 0.7705 - val_loss: 0.4975 - val_acc: 0.7896\n",
      "Epoch 620/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5013 - acc: 0.7815 - val_loss: 0.4941 - val_acc: 0.7945\n",
      "Epoch 621/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4813 - acc: 0.7889 - val_loss: 0.4926 - val_acc: 0.7917\n",
      "Epoch 622/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4868 - acc: 0.7825 - val_loss: 0.4938 - val_acc: 0.7869\n",
      "Epoch 623/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4897 - acc: 0.7792 - val_loss: 0.4933 - val_acc: 0.7924\n",
      "Epoch 624/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4939 - acc: 0.7795 - val_loss: 0.4911 - val_acc: 0.7903\n",
      "Epoch 625/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4936 - acc: 0.7788 - val_loss: 0.4922 - val_acc: 0.7945\n",
      "Epoch 626/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4980 - acc: 0.7820 - val_loss: 0.4934 - val_acc: 0.7931\n",
      "Epoch 627/2000\n",
      "4335/4335 [==============================] - 0s 24us/step - loss: 0.4921 - acc: 0.7811 - val_loss: 0.4915 - val_acc: 0.7875\n",
      "Epoch 628/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4919 - acc: 0.7790 - val_loss: 0.4935 - val_acc: 0.7924\n",
      "Epoch 629/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4856 - acc: 0.7894 - val_loss: 0.4933 - val_acc: 0.7862\n",
      "Epoch 630/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4907 - acc: 0.7760 - val_loss: 0.4927 - val_acc: 0.7875\n",
      "Epoch 631/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4871 - acc: 0.7820 - val_loss: 0.4954 - val_acc: 0.7848\n",
      "Epoch 632/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4989 - acc: 0.7792 - val_loss: 0.4964 - val_acc: 0.7903\n",
      "Epoch 633/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4917 - acc: 0.7859 - val_loss: 0.4949 - val_acc: 0.7896\n",
      "Epoch 634/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4953 - acc: 0.7797 - val_loss: 0.4943 - val_acc: 0.7875\n",
      "Epoch 635/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4922 - acc: 0.7769 - val_loss: 0.4937 - val_acc: 0.7924\n",
      "Epoch 636/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4849 - acc: 0.7829 - val_loss: 0.4956 - val_acc: 0.7875\n",
      "Epoch 637/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4929 - acc: 0.7753 - val_loss: 0.4977 - val_acc: 0.7903\n",
      "Epoch 638/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4868 - acc: 0.7832 - val_loss: 0.4936 - val_acc: 0.7924\n",
      "Epoch 639/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4883 - acc: 0.7889 - val_loss: 0.4936 - val_acc: 0.7924\n",
      "Epoch 640/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.5016 - acc: 0.7723 - val_loss: 0.4963 - val_acc: 0.7945\n",
      "Epoch 641/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4899 - acc: 0.7866 - val_loss: 0.5006 - val_acc: 0.7924\n",
      "Epoch 642/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.4935 - acc: 0.7866 - val_loss: 0.4937 - val_acc: 0.7903\n",
      "Epoch 643/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.4890 - acc: 0.7866 - val_loss: 0.4940 - val_acc: 0.7903\n",
      "Epoch 644/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.4947 - acc: 0.7792 - val_loss: 0.4941 - val_acc: 0.7889\n",
      "Epoch 645/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.4947 - acc: 0.7802 - val_loss: 0.4935 - val_acc: 0.7882\n",
      "Epoch 646/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.4888 - acc: 0.7806 - val_loss: 0.5002 - val_acc: 0.7917\n",
      "Epoch 647/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.4916 - acc: 0.7744 - val_loss: 0.4936 - val_acc: 0.7882\n",
      "Epoch 648/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.4859 - acc: 0.7896 - val_loss: 0.4968 - val_acc: 0.7917\n",
      "Epoch 649/2000\n",
      "4335/4335 [==============================] - 0s 27us/step - loss: 0.4954 - acc: 0.7795 - val_loss: 0.4940 - val_acc: 0.7869\n",
      "Epoch 650/2000\n",
      "4335/4335 [==============================] - 0s 26us/step - loss: 0.4865 - acc: 0.7832 - val_loss: 0.4933 - val_acc: 0.7924\n",
      "Epoch 651/2000\n",
      "4335/4335 [==============================] - 0s 28us/step - loss: 0.4928 - acc: 0.7799 - val_loss: 0.4927 - val_acc: 0.7896\n",
      "Epoch 652/2000\n",
      "4335/4335 [==============================] - 0s 28us/step - loss: 0.4876 - acc: 0.7827 - val_loss: 0.4919 - val_acc: 0.7875\n",
      "Epoch 653/2000\n",
      "4335/4335 [==============================] - 0s 28us/step - loss: 0.4921 - acc: 0.7848 - val_loss: 0.4938 - val_acc: 0.7924\n",
      "Epoch 654/2000\n",
      "4335/4335 [==============================] - 0s 25us/step - loss: 0.4959 - acc: 0.7762 - val_loss: 0.4932 - val_acc: 0.7889\n",
      "Epoch 655/2000\n",
      "4335/4335 [==============================] - 0s 23us/step - loss: 0.4869 - acc: 0.7818 - val_loss: 0.4960 - val_acc: 0.7924\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, y_tr, validation_data=(X_ts, y_ts), epochs = 2000, callbacks = [es]) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_CC_ADAM_Classifier_DS2_NewThreshold_2000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(history, open(\"history_CC_ADAM_Classifier_DS2_NewThreshold_2000.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
